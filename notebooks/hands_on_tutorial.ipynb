{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeCTIaEG3DJz"
      },
      "source": [
        "# Hands-on tutorial: Privacy Concerns in LLMs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQvkVv9mbYG8"
      },
      "source": [
        "## Introduction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwJ_RlJwklGI"
      },
      "source": [
        "## Prompt Injection Attacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ls6yVhUEkr9m"
      },
      "source": [
        "## LLM Guard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_RJsTcmkwDc"
      },
      "source": [
        "### Input Guard Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PcKO64Zk4dS"
      },
      "source": [
        "### LLM Guard: Simulation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtQE_X6klRmq"
      },
      "source": [
        "## Streamlit Demo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "source": [
        "Run `make st-run` in the terminal to start the LLMGuard Streamlit app."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Future Work"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Extend the LLM Guard to other LLM sdks other than openai.\n",
        "- Investigate what kind of checks could be implemented in the output guard."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sbWte7BvBZm"
      },
      "source": [
        "## References\n",
        "- [On Protecting the Data Privacy of Large Language\n",
        "Models (LLMs): A Survey](https://arxiv.org/pdf/2403.05156)\n",
        "- [Prompt Injection attack against LLM-integrated Applications](https://arxiv.org/pdf/2306.05499)\n",
        "- [What is Gandalf?](https://www.lakera.ai/blog/who-is-gandalf)\n",
        "- [Malicious Prompts Dataset](https://huggingface.co/datasets/ahsanayub/malicious-prompts)\n",
        "- [Embedding-based classifiers can detect prompt injection\n",
        "attacks](https://arxiv.org/pdf/2410.22284)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
